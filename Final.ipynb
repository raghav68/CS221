{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 332458\n",
      "CORD UIDs (new: 1938, removed: 409)\n",
      "\n",
      "Full text:\n",
      "  PDF - 123513 json (new: 549, removed: 3136)\n",
      "  PMC - 91446 json (new: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-10-31\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 330801\n",
      "CORD UIDs (new: 8221, removed: 71)\n",
      "\n",
      "Full text:\n",
      "  PDF - 126099 json (new: 1005, removed: 557)\n",
      "  PMC - 91444 json (new: 474)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-10-29\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 322441\n",
      "CORD UIDs (new: 4697, removed: 1314)\n",
      "\n",
      "Full text:\n",
      "  PDF - 125651 json (new: 3179, removed: 209)\n",
      "  PMC - 90970 json (new: 305, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-10-28\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 320518\n",
      "CORD UIDs (new: 1290, removed: 409)\n",
      "\n",
      "Full text:\n",
      "  PDF - 122679 json (new: 1311, removed: 616)\n",
      "  PMC - 90666 json (new: 512, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-10-27\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 319615\n",
      "CORD UIDs (new: 1314, removed: 459)\n",
      "\n",
      "Full text:\n",
      "  PDF - 121983 json (new: 616, removed: 1783)\n",
      "  PMC - 90155 json (new: 493)\n",
      "\n",
      "---------------------------\n",
      "2020-10-26\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 318787\n",
      "CORD UIDs (new: 651, removed: 2)\n",
      "\n",
      "Full text:\n",
      "  PDF - 123149 json (new: 1424, removed: 1389)\n",
      "  PMC - 89662 json (new: 231, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "2020-10-25\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 318137\n",
      "CORD UIDs (new: 985, removed: 5)\n",
      "\n",
      "Full text:\n",
      "  PDF - 123114 json (new: 1549, removed: 593)\n",
      "  PMC - 89432 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-10-24\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 317151\n",
      "CORD UIDs (new: 1185, removed: 12)\n",
      "\n",
      "Full text:\n",
      "  PDF - 122156 json (new: 1569, removed: 619)\n",
      "  PMC - 89432 json (new: 650, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-10-23\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 315948\n",
      "CORD UIDs (new: 1870, removed: 14)\n",
      "\n",
      "Full text:\n",
      "  PDF - 121206 json (new: 2006, removed: 79)\n",
      "  PMC - 88783 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-10-22\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 314001\n",
      "CORD UIDs (new: 2341, removed: 31)\n",
      "\n",
      "Full text:\n",
      "  PDF - 119277 json (new: 142, removed: 2439)\n",
      "  PMC - 88783 json (new: 680)\n",
      "\n",
      "---------------------------\n",
      "2020-10-21\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 311616\n",
      "CORD UIDs (new: 964, removed: 178)\n",
      "\n",
      "Full text:\n",
      "  PDF - 121574 json (new: 2791, removed: 240)\n",
      "  PMC - 88103 json (new: 0, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-10-20\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 310834\n",
      "CORD UIDs (new: 1514, removed: 5)\n",
      "\n",
      "Full text:\n",
      "  PDF - 119022 json (new: 777, removed: 2028)\n",
      "  PMC - 88104 json (new: 2569)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-10-19\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 309325\n",
      "CORD UIDs (new: 123, removed: 50)\n",
      "\n",
      "Full text:\n",
      "  PDF - 120272 json (new: 1965, removed: 437)\n",
      "  PMC - 85535 json (new: 0, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-10-18\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 309204\n",
      "CORD UIDs (new: 2055, removed: 237)\n",
      "\n",
      "Full text:\n",
      "  PDF - 118743 json (new: 1574, removed: 293)\n",
      "  PMC - 85537 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-10-17\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 307357\n",
      "CORD UIDs (new: 597, removed: 0)\n",
      "\n",
      "Full text:\n",
      "  PDF - 117461 json (new: 750, removed: 81)\n",
      "  PMC - 85537 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-10-16\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 306729\n",
      "CORD UIDs (new: 1231, removed: 44)\n",
      "\n",
      "Full text:\n",
      "  PDF - 116791 json (new: 197, removed: 3068)\n",
      "  PMC - 85537 json (new: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-10-15\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 305354\n",
      "CORD UIDs (new: 1057, removed: 131)\n",
      "\n",
      "Full text:\n",
      "  PDF - 119661 json (new: 1665, removed: 227)\n",
      "  PMC - 85535 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-10-14\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 304350\n",
      "CORD UIDs (new: 2046, removed: 158)\n",
      "\n",
      "Full text:\n",
      "  PDF - 118221 json (new: 2095, removed: 352)\n",
      "  PMC - 85535 json (new: 7, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-10-12\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 302449\n",
      "CORD UIDs (new: 744, removed: 66)\n",
      "\n",
      "Full text:\n",
      "  PDF - 116478 json (new: 442, removed: 2813)\n",
      "  PMC - 85530 json (new: 471)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "2020-10-11\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 301667\n",
      "CORD UIDs (new: 2143, removed: 459)\n",
      "\n",
      "Full text:\n",
      "  PDF - 118848 json (new: 3608, removed: 198)\n",
      "  PMC - 85059 json (new: 1, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-10-10\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 299821\n",
      "CORD UIDs (new: 5173, removed: 34)\n",
      "\n",
      "Full text:\n",
      "  PDF - 115437 json (new: 308, removed: 2783)\n",
      "  PMC - 85059 json (new: 361)\n",
      "\n",
      "---------------------------\n",
      "2020-10-09\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 294542\n",
      "CORD UIDs (new: 904, removed: 69)\n",
      "\n",
      "Full text:\n",
      "  PDF - 117911 json (new: 2584, removed: 337)\n",
      "  PMC - 84698 json (new: 0, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-10-08\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 293598\n",
      "CORD UIDs (new: 3837, removed: 134)\n",
      "\n",
      "Full text:\n",
      "  PDF - 115663 json (new: 705, removed: 499)\n",
      "  PMC - 84700 json (new: 732)\n",
      "\n",
      "---------------------------\n",
      "2020-10-07\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 289825\n",
      "CORD UIDs (new: 1191, removed: 224)\n",
      "\n",
      "Full text:\n",
      "  PDF - 115455 json (new: 1961, removed: 419)\n",
      "  PMC - 83968 json (new: 173)\n",
      "\n",
      "---------------------------\n",
      "2020-10-06\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 288800\n",
      "CORD UIDs (new: 1213, removed: 237)\n",
      "\n",
      "Full text:\n",
      "  PDF - 113913 json (new: 96, removed: 2355)\n",
      "  PMC - 83795 json (new: 434)\n",
      "\n",
      "---------------------------\n",
      "2020-10-05\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 287836\n",
      "CORD UIDs (new: 430, removed: 2)\n",
      "\n",
      "Full text:\n",
      "  PDF - 116172 json (new: 971, removed: 815)\n",
      "  PMC - 83361 json (new: 491)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-10-04\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 287405\n",
      "CORD UIDs (new: 667, removed: 40)\n",
      "\n",
      "Full text:\n",
      "  PDF - 116015 json (new: 2763, removed: 276)\n",
      "  PMC - 82870 json (new: 0, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-10-03\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 286748\n",
      "CORD UIDs (new: 1733, removed: 147)\n",
      "\n",
      "Full text:\n",
      "  PDF - 113526 json (new: 1044, removed: 503)\n",
      "  PMC - 82872 json (new: 597)\n",
      "\n",
      "---------------------------\n",
      "2020-10-01\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 284965\n",
      "CORD UIDs (new: 2388, removed: 200)\n",
      "\n",
      "Full text:\n",
      "  PDF - 112985 json (new: 1335, removed: 1474)\n",
      "  PMC - 82275 json (new: 602)\n",
      "\n",
      "---------------------------\n",
      "2020-09-28\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 282714\n",
      "CORD UIDs (new: 682, removed: 5)\n",
      "\n",
      "Full text:\n",
      "  PDF - 113120 json (new: 1098, removed: 826)\n",
      "  PMC - 81673 json (new: 412, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-09-27\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 282025\n",
      "CORD UIDs (new: 1390, removed: 120)\n",
      "\n",
      "Full text:\n",
      "  PDF - 112847 json (new: 861, removed: 1248)\n",
      "  PMC - 81262 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-09-26\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 280697\n",
      "CORD UIDs (new: 1396, removed: 306)\n",
      "\n",
      "Full text:\n",
      "  PDF - 113234 json (new: 1767, removed: 205)\n",
      "  PMC - 81262 json (new: 1, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-09-25\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 279475\n",
      "CORD UIDs (new: 2407, removed: 33)\n",
      "\n",
      "Full text:\n",
      "  PDF - 111671 json (new: 1818, removed: 65)\n",
      "  PMC - 81262 json (new: 420)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-09-24\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 277018\n",
      "CORD UIDs (new: 1755, removed: 117)\n",
      "\n",
      "Full text:\n",
      "  PDF - 109916 json (new: 293, removed: 1635)\n",
      "  PMC - 80842 json (new: 516)\n",
      "\n",
      "---------------------------\n",
      "2020-09-23\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 275270\n",
      "CORD UIDs (new: 1532, removed: 274)\n",
      "\n",
      "Full text:\n",
      "  PDF - 111258 json (new: 1455, removed: 639)\n",
      "  PMC - 80326 json (new: 88)\n",
      "\n",
      "---------------------------\n",
      "2020-09-22\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 274033\n",
      "CORD UIDs (new: 610, removed: 2)\n",
      "\n",
      "Full text:\n",
      "  PDF - 110440 json (new: 1089, removed: 1084)\n",
      "  PMC - 80238 json (new: 625)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-09-21\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 273419\n",
      "CORD UIDs (new: 378, removed: 2)\n",
      "\n",
      "Full text:\n",
      "  PDF - 110434 json (new: 1282, removed: 891)\n",
      "  PMC - 79613 json (new: 383)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-09-20\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 273040\n",
      "CORD UIDs (new: 2172, removed: 138)\n",
      "\n",
      "Full text:\n",
      "  PDF - 110043 json (new: 2682, removed: 1117)\n",
      "  PMC - 79230 json (new: 0, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-09-19\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 270934\n",
      "CORD UIDs (new: 2737, removed: 838)\n",
      "\n",
      "Full text:\n",
      "  PDF - 108476 json (new: 575, removed: 1931)\n",
      "  PMC - 79232 json (new: 309)\n",
      "\n",
      "---------------------------\n",
      "2020-09-18\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 268164\n",
      "CORD UIDs (new: 2395, removed: 59)\n",
      "\n",
      "Full text:\n",
      "  PDF - 109832 json (new: 1533, removed: 512)\n",
      "  PMC - 78923 json (new: 297)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-09-17\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 266175\n",
      "CORD UIDs (new: 105, removed: 48)\n",
      "\n",
      "Full text:\n",
      "  PDF - 108809 json (new: 2576, removed: 27)\n",
      "  PMC - 78626 json (new: 0, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-09-16\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 266073\n",
      "CORD UIDs (new: 3716, removed: 253)\n",
      "\n",
      "Full text:\n",
      "  PDF - 106259 json (new: 1457, removed: 1450)\n",
      "  PMC - 78627 json (new: 340)\n",
      "\n",
      "---------------------------\n",
      "2020-09-15\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 262515\n",
      "CORD UIDs (new: 1740, removed: 576)\n",
      "\n",
      "Full text:\n",
      "  PDF - 106251 json (new: 898, removed: 703)\n",
      "  PMC - 78287 json (new: 966)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "2020-09-14\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 261133\n",
      "CORD UIDs (new: 7649, removed: 216)\n",
      "\n",
      "Full text:\n",
      "  PDF - 106055 json (new: 686, removed: 776)\n",
      "  PMC - 77321 json (new: 0)\n",
      "\n",
      "---------------------------s\n",
      "\n",
      "\n",
      "2020-09-11\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 253454\n",
      "CORD UIDs (new: 1934, removed: 255)\n",
      "\n",
      "Full text:\n",
      "  PDF - 106144 json (new: 1078, removed: 494)\n",
      "  PMC - 77321 json (new: 786)\n",
      "\n",
      "---------------------------\n",
      "2020-09-09\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 251733\n",
      "CORD UIDs (new: 1840, removed: 601)\n",
      "\n",
      "Full text:\n",
      "  PDF - 105559 json (new: 1433, removed: 508)\n",
      "  PMC - 76535 json (new: 1)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-09-08\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 250165\n",
      "CORD UIDs (new: 5093, removed: 325)\n",
      "\n",
      "Full text:\n",
      "  PDF - 104633 json (new: 2665, removed: 1171)\n",
      "  PMC - 76534 json (new: 988)\n",
      "\n",
      "---------------------------\n",
      "2020-09-03\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 245057\n",
      "CORD UIDs (new: 2032, removed: 855)\n",
      "\n",
      "Full text:\n",
      "  PDF - 103138 json (new: 1317, removed: 811)\n",
      "  PMC - 75546 json (new: 913, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-09-02\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 243822\n",
      "CORD UIDs (new: 1651, removed: 13)\n",
      "\n",
      "Full text:\n",
      "  PDF - 102631 json (new: 2579, removed: 379)\n",
      "  PMC - 74634 json (new: 498, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-09-01\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 242164\n",
      "CORD UIDs (new: 3390, removed: 296)\n",
      "\n",
      "Full text:\n",
      "  PDF - 100431 json (new: 1217, removed: 160)\n",
      "  PMC - 74137 json (new: 704)\n",
      "\n",
      "---------------------------\n",
      "2020-08-29\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 239000\n",
      "CORD UIDs (new: 440, removed: 123)\n",
      "\n",
      "Full text:\n",
      "  PDF - 99372 json (new: 558, removed: 1695)\n",
      "  PMC - 73433 json (new: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-08-28\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 238674\n",
      "CORD UIDs (new: 1451, removed: 60)\n",
      "\n",
      "Full text:\n",
      "  PDF - 100508 json (new: 1456, removed: 292)\n",
      "  PMC - 73431 json (new: 515)\n",
      "\n",
      "\n",
      "2020-08-27\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 237207\n",
      "CORD UIDs (new: 1653, removed: 270)\n",
      "\n",
      "Full text:\n",
      "  PDF - 99343 json (new: 222, removed: 887)\n",
      "  PMC - 72916 json (new: 586)\n",
      "\n",
      "---------------------------\n",
      "2020-08-26\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 235767\n",
      "CORD UIDs (new: 1457, removed: 22)\n",
      "\n",
      "Full text:\n",
      "  PDF - 100008 json (new: 1030, removed: 547)\n",
      "  PMC - 72330 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-08-25\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 234284\n",
      "CORD UIDs (new: 747, removed: 4)\n",
      "\n",
      "Full text:\n",
      "  PDF - 99524 json (new: 201, removed: 672)\n",
      "  PMC - 72330 json (new: 505)\n",
      "\n",
      "---------------------------\n",
      "2020-08-24\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 233539\n",
      "CORD UIDs (new: 257, removed: 32)\n",
      "\n",
      "Full text:\n",
      "  PDF - 99994 json (new: 484, removed: 1889)\n",
      "  PMC - 71825 json (new: 251)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-08-23\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 233284\n",
      "CORD UIDs (new: 2137, removed: 761)\n",
      "\n",
      "Full text:\n",
      "  PDF - 101398 json (new: 3424, removed: 188)\n",
      "  PMC - 71574 json (new: 0, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-08-22\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 231812\n",
      "CORD UIDs (new: 1843, removed: 10780)\n",
      "\n",
      "Full text:\n",
      "  PDF - 98161 json (new: 309, removed: 2726)\n",
      "  PMC - 71576 json (new: 335)\n",
      "\n",
      "---------------------------\n",
      "2020-08-21\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 230323\n",
      "CORD UIDs (new: 431, removed: 3)\n",
      "\n",
      "Full text:\n",
      "  PDF - 100576 json (new: 3897, removed: 191)\n",
      "  PMC - 71241 json (new: 0, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-08-20\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 229892\n",
      "CORD UIDs (new: 1309, removed: 6)\n",
      "\n",
      "Full text:\n",
      "  PDF - 96868 json (new: 1295, removed: 265)\n",
      "  PMC - 71243 json (new: 624)\n",
      "\n",
      "---------------------------\n",
      "2020-08-19\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 228592\n",
      "CORD UIDs (new: 1147, removed: 3)\n",
      "\n",
      "Full text:\n",
      "  PDF - 95838 json (new: 1011, removed: 561)\n",
      "  PMC - 70619 json (new: 341)\n",
      "\n",
      "---------------------------\n",
      "2020-08-18\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 227448\n",
      "CORD UIDs (new: 349, removed: 3)\n",
      "\n",
      "Full text:\n",
      "  PDF - 95387 json (new: 211, removed: 2434)\n",
      "  PMC - 70278 json (new: 369)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2020-08-17\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 227102\n",
      "CORD UIDs (new: 493, removed: 3)\n",
      "\n",
      "Full text:\n",
      "  PDF - 97609 json (new: 1783, removed: 397)\n",
      "  PMC - 69909 json (new: 0, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-08-16\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 226612\n",
      "CORD UIDs (new: 2037, removed: 61)\n",
      "\n",
      "Full text:\n",
      "  PDF - 96222 json (new: 1112, removed: 469)\n",
      "  PMC - 69910 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-08-15\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 224653\n",
      "CORD UIDs (new: 11388, removed: 2238)\n",
      "\n",
      "Full text:\n",
      "  PDF - 95578 json (new: 703, removed: 1087)\n",
      "  PMC - 69910 json (new: 300)\n",
      "\n",
      "\n",
      "---------------------------\n",
      "\n",
      "2020-08-13\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 215527\n",
      "CORD UIDs (new: 2301, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 94613 json (new: 393, removed: 3231)\n",
      "  PMC - 69610 json (new: 349)\n",
      "\n",
      "---------------------------\n",
      "2020-08-12\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 213210\n",
      "CORD UIDs (new: 486, removed: 2)\n",
      "\n",
      "Full text:\n",
      "  PDF - 97450 json (new: 1860, removed: 20)\n",
      "  PMC - 69261 json (new: 282, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-08-11\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 212725\n",
      "CORD UIDs (new: 832, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 95609 json (new: 2445, removed: 412)\n",
      "  PMC - 68980 json (new: 474, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-08-10\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 211900\n",
      "CORD UIDs (new: 1360, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 93575 json (new: 905, removed: 971)\n",
      "  PMC - 68507 json (new: 316)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "\n",
      "2020-08-08\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 210537\n",
      "CORD UIDs (new: 357, removed: 1112)\n",
      "\n",
      "Full text:\n",
      "  PDF - 93640 json (new: 951, removed: 1344)\n",
      "  PMC - 68191 json (new: 208, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-08-07\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 211233\n",
      "CORD UIDs (new: 830, removed: 8)\n",
      "\n",
      "Full text:\n",
      "  PDF - 94032 json (new: 1811, removed: 581)\n",
      "  PMC - 67984 json (new: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-08-06\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 210405\n",
      "CORD UIDs (new: 1369, removed: 14)\n",
      "\n",
      "Full text:\n",
      "  PDF - 92801 json (new: 432, removed: 2357)\n",
      "  PMC - 67983 json (new: 995)\n",
      "\n",
      "---------------------------\n",
      "2020-08-05\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 209039\n",
      "CORD UIDs (new: 1448, removed: 12)\n",
      "\n",
      "Full text:\n",
      "  PDF - 94725 json (new: 295, removed: 17)\n",
      "  PMC - 66988 json (new: 137)\n",
      "\n",
      "---------------------------\n",
      "2020-08-04\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 207595\n",
      "CORD UIDs (new: 290, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 94446 json (new: 1446, removed: 261)\n",
      "  PMC - 66851 json (new: 336, removed: 1)\n",
      "\n",
      "\n",
      "\n",
      "2020-08-03\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 207311\n",
      "CORD UIDs (new: 573, removed: 6)\n",
      "\n",
      "Full text:\n",
      "  PDF - 93260 json (new: 398, removed: 1142)\n",
      "  PMC - 66516 json (new: 352)\n",
      "\n",
      "---------------------------\n",
      "2020-08-02\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 206743\n",
      "CORD UIDs (new: 1033, removed: 6)\n",
      "\n",
      "Full text:\n",
      "  PDF - 94003 json (new: 2582, removed: 202)\n",
      "  PMC - 66164 json (new: 0, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-08-01\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 205709\n",
      "CORD UIDs (new: 890, removed: 4)\n",
      "\n",
      "Full text:\n",
      "  PDF - 91622 json (new: 1545, removed: 292)\n",
      "  PMC - 66165 json (new: 174, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-07-31\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 204823\n",
      "CORD UIDs (new: 1290, removed: 8)\n",
      "\n",
      "Full text:\n",
      "  PDF - 90367 json (new: 428, removed: 3115)\n",
      "  PMC - 65992 json (new: 337)\n",
      "\n",
      "---------------------------\n",
      "2020-07-30\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 203522\n",
      "CORD UIDs (new: 400, removed: 8)\n",
      "\n",
      "Full text:\n",
      "  PDF - 93054 json (new: 3123, removed: 166)\n",
      "  PMC - 65655 json (new: 0, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-07-29\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 203128\n",
      "CORD UIDs (new: 994, removed: 4)\n",
      "\n",
      "Full text:\n",
      "  PDF - 90095 json (new: 1298, removed: 1345)\n",
      "  PMC - 65656 json (new: 431)\n",
      "\n",
      "---------------------------\n",
      "2020-07-28\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 202139\n",
      "CORD UIDs (new: 3021, removed: 18)\n",
      "\n",
      "Full text:\n",
      "  PDF - 90142 json (new: 1881, removed: 1243)\n",
      "  PMC - 65225 json (new: 176, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-07-27\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 199092\n",
      "CORD UIDs (new: 499, removed: 1)\n",
      "\n",
      "Full text:\n",
      "  PDF - 89503 json (new: 721, removed: 359)\n",
      "  PMC - 65050 json (new: 294, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-07-25\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 198594\n",
      "CORD UIDs (new: 256, removed: 0)\n",
      "\n",
      "Full text:\n",
      "  PDF - 89140 json (new: 504, removed: 2408)\n",
      "  PMC - 64757 json (new: 266)\n",
      "\n",
      "---------------------------\n",
      "2020-07-24\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 198338\n",
      "CORD UIDs (new: 211, removed: 5)\n",
      "\n",
      "Full text:\n",
      "  PDF - 91043 json (new: 2501, removed: 129)\n",
      "  PMC - 64491 json (new: 302, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-07-23\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 198129\n",
      "CORD UIDs (new: 718, removed: 9)\n",
      "\n",
      "Full text:\n",
      "  PDF - 88670 json (new: 1404, removed: 28)\n",
      "  PMC - 64191 json (new: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-07-22\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 197412\n",
      "CORD UIDs (new: 783, removed: 4)\n",
      "\n",
      "Full text:\n",
      "  PDF - 87293 json (new: 835, removed: 397)\n",
      "  PMC - 64190 json (new: 567)\n",
      "\n",
      "---------------------------\n",
      "2020-07-21\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 196630\n",
      "CORD UIDs (new: 904, removed: 3)\n",
      "\n",
      "Full text:\n",
      "  PDF - 86853 json (new: 854, removed: 1636)\n",
      "  PMC - 63623 json (new: 229)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "\n",
      "2020-07-20\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 195711\n",
      "CORD UIDs (new: 3175, removed: 17)\n",
      "\n",
      "Full text:\n",
      "  PDF - 87634 json (new: 3296, removed: 89)\n",
      "  PMC - 63394 json (new: 658)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "\n",
      "2020-07-16\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 192509\n",
      "CORD UIDs (new: 1176, removed: 17)\n",
      "\n",
      "Full text:\n",
      "  PDF - 84426 json (new: 804, removed: 1829)\n",
      "  PMC - 62736 json (new: 770)\n",
      "\n",
      "---------------------------\n",
      "2020-07-15\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 191355\n",
      "CORD UIDs (new: 717, removed: 6)\n",
      "\n",
      "Full text:\n",
      "  PDF - 85451 json (new: 1428, removed: 1491)\n",
      "  PMC - 61966 json (new: 341, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-07-14\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 190647\n",
      "CORD UIDs (new: 1256, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 85513 json (new: 2190, removed: 320)\n",
      "  PMC - 61626 json (new: 541)\n",
      "\n",
      "---------------------------\n",
      "2020-07-13\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 189384\n",
      "CORD UIDs (new: 1457, removed: 17)\n",
      "\n",
      "Full text:\n",
      "  PDF - 83641 json (new: 831, removed: 75)\n",
      "  PMC - 61085 json (new: 363)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "\n",
      "2020-07-12\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 187938\n",
      "CORD UIDs (new: 647, removed: 1)\n",
      "\n",
      "Full text:\n",
      "  PDF - 82884 json (new: 317, removed: 3604)\n",
      "  PMC - 60722 json (new: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-07-11\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 187291\n",
      "CORD UIDs (new: 359, removed: 4)\n",
      "\n",
      "Full text:\n",
      "  PDF - 86171 json (new: 2986, removed: 313)\n",
      "  PMC - 60720 json (new: 7, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-07-10\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 186929\n",
      "CORD UIDs (new: 850, removed: 6)\n",
      "\n",
      "Full text:\n",
      "  PDF - 83496 json (new: 366, removed: 2446)\n",
      "  PMC - 60715 json (new: 468, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-07-09\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 186084\n",
      "CORD UIDs (new: 1153, removed: 4)\n",
      "\n",
      "Full text:\n",
      "  PDF - 85576 json (new: 3244, removed: 143)\n",
      "  PMC - 60249 json (new: 265, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-07-08\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 184929\n",
      "CORD UIDs (new: 1758, removed: 2)\n",
      "\n",
      "Full text:\n",
      "  PDF - 82474 json (new: 1749, removed: 109)\n",
      "  PMC - 59986 json (new: 272, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "2020-07-07\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 183141\n",
      "CORD UIDs (new: 869, removed: 54)\n",
      "\n",
      "Full text:\n",
      "  PDF - 80833 json (new: 481, removed: 3085)\n",
      "  PMC - 59716 json (new: 767)\n",
      "\n",
      "---------------------------\n",
      "2020-07-06\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 182328\n",
      "CORD UIDs (new: 546, removed: 3)\n",
      "\n",
      "Full text:\n",
      "  PDF - 83436 json (new: 2988, removed: 304)\n",
      "  PMC - 58949 json (new: 1, removed: 2)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "2020-07-05\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 181778\n",
      "CORD UIDs (new: 319, removed: 2)\n",
      "\n",
      "Full text:\n",
      "  PDF - 80750 json (new: 838, removed: 526)\n",
      "  PMC - 58950 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-07-04\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 181456\n",
      "CORD UIDs (new: 1294, removed: 33)\n",
      "\n",
      "Full text:\n",
      "  PDF - 80438 json (new: 729, removed: 789)\n",
      "  PMC - 58950 json (new: 232, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-07-03\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 180153\n",
      "CORD UIDs (new: 9671, removed: 49)\n",
      "\n",
      "Full text:\n",
      "  PDF - 80497 json (new: 2295, removed: 547)\n",
      "  PMC - 58719 json (new: 770, removed: 5)\n",
      "\n",
      "---------------------------\n",
      "2020-07-01\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 169821\n",
      "CORD UIDs (new: 1157, removed: 13)\n",
      "\n",
      "Full text:\n",
      "  PDF - 78747 json (new: 715, removed: 1424)\n",
      "  PMC - 57954 json (new: 687)\n",
      "\n",
      "---------------------------\n",
      "2020-06-30\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 168679\n",
      "CORD UIDs (new: 874, removed: 12)\n",
      "\n",
      "Full text:\n",
      "  PDF - 79455 json (new: 1569, removed: 140)\n",
      "  PMC - 57267 json (new: 2, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-29\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 167822\n",
      "CORD UIDs (new: 335, removed: 3)\n",
      "\n",
      "Full text:\n",
      "  PDF - 78025 json (new: 241, removed: 1355)\n",
      "  PMC - 57266 json (new: 229)\n",
      "\n",
      "---------------------------\n",
      "2020-06-28\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 167470\n",
      "CORD UIDs (new: 3603, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 79138 json (new: 1638, removed: 208)\n",
      "  PMC - 57037 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-06-27\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 163835\n",
      "CORD UIDs (new: 292, removed: 1)\n",
      "\n",
      "Full text:\n",
      "  PDF - 77707 json (new: 242, removed: 3168)\n",
      "  PMC - 57037 json (new: 15)\n",
      "\n",
      "---------------------------\n",
      "2020-06-26\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 163544\n",
      "CORD UIDs (new: 2011, removed: 29)\n",
      "\n",
      "Full text:\n",
      "  PDF - 80632 json (new: 3122, removed: 55)\n",
      "  PMC - 57022 json (new: 556, removed: 3)\n",
      "\n",
      "---------------------------\n",
      "2020-06-25\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 161564\n",
      "CORD UIDs (new: 1486, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 77564 json (new: 1957, removed: 1067)\n",
      "  PMC - 56469 json (new: 308, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-24\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 160082\n",
      "CORD UIDs (new: 838, removed: 1110)\n",
      "\n",
      "Full text:\n",
      "  PDF - 76674 json (new: 607, removed: 2595)\n",
      "  PMC - 56162 json (new: 498, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-23\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 160356\n",
      "CORD UIDs (new: 1413, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 78660 json (new: 3670, removed: 319)\n",
      "  PMC - 55665 json (new: 965, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-22\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 158947\n",
      "CORD UIDs (new: 103, removed: 3)\n",
      "\n",
      "Full text:\n",
      "  PDF - 75308 json (new: 113, removed: 2171)\n",
      "  PMC - 54701 json (new: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-21\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 158847\n",
      "CORD UIDs (new: 128, removed: 2)\n",
      "\n",
      "Full text:\n",
      "  PDF - 77366 json (new: 1030, removed: 594)\n",
      "  PMC - 54700 json (new: 0, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-20\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 158721\n",
      "CORD UIDs (new: 453, removed: 8)\n",
      "\n",
      "Full text:\n",
      "  PDF - 76928 json (new: 978, removed: 659)\n",
      "  PMC - 54701 json (new: 571, removed: 7)\n",
      "\n",
      "---------------------------\n",
      "2020-06-19\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 158274\n",
      "CORD UIDs (new: 573, removed: 10)\n",
      "\n",
      "Full text:\n",
      "  PDF - 76608 json (new: 834, removed: 18)\n",
      "  PMC - 54137 json (new: 1, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-18\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 157712\n",
      "CORD UIDs (new: 323, removed: 6)\n",
      "\n",
      "Full text:\n",
      "  PDF - 75791 json (new: 1718, removed: 883)\n",
      "  PMC - 54137 json (new: 404, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-17\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 157394\n",
      "CORD UIDs (new: 11122, removed: 10)\n",
      "\n",
      "Full text:\n",
      "  PDF - 74955 json (new: 2648, removed: 305)\n",
      "  PMC - 53734 json (new: 286)\n",
      "\n",
      "---------------------------\n",
      "2020-06-16\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 146525\n",
      "CORD UIDs (new: 3596, removed: 19)\n",
      "\n",
      "Full text:\n",
      "  PDF - 72612 json (new: 690, removed: 763)\n",
      "  PMC - 53448 json (new: 358)\n",
      "\n",
      "---------------------------\n",
      "2020-06-15\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 142905\n",
      "CORD UIDs (new: 471, removed: 3)\n",
      "\n",
      "Full text:\n",
      "  PDF - 72683 json (new: 961, removed: 263)\n",
      "  PMC - 53090 json (new: 470)\n",
      "\n",
      "---------------------------\n",
      "2020-06-14\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 142436\n",
      "CORD UIDs (new: 859, removed: 1)\n",
      "\n",
      "Full text:\n",
      "  PDF - 71984 json (new: 500, removed: 1218)\n",
      "  PMC - 52620 json (new: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-13\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 141575\n",
      "CORD UIDs (new: 791, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 72702 json (new: 1669, removed: 996)\n",
      "  PMC - 52619 json (new: 6, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-12\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 140780\n",
      "CORD UIDs (new: 280, removed: 1)\n",
      "\n",
      "Full text:\n",
      "  PDF - 72027 json (new: 258, removed: 1943)\n",
      "  PMC - 52614 json (new: 270, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-11\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 140499\n",
      "CORD UIDs (new: 706, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 73711 json (new: 3706, removed: 425)\n",
      "  PMC - 52345 json (new: 452, removed: 4)\n",
      "\n",
      "---------------------------\n",
      "2020-06-10\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 139792\n",
      "CORD UIDs (new: 1006, removed: 8)\n",
      "\n",
      "Full text:\n",
      "  PDF - 70430 json (new: 1599, removed: 823)\n",
      "  PMC - 51897 json (new: 1079)\n",
      "\n",
      "---------------------------\n",
      "2020-06-09\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 138794\n",
      "CORD UIDs (new: 1388, removed: 9)\n",
      "\n",
      "Full text:\n",
      "  PDF - 69652 json (new: 2817, removed: 324)\n",
      "  PMC - 50818 json (new: 17)\n",
      "\n",
      "---------------------------\n",
      "2020-06-08\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 137411\n",
      "CORD UIDs (new: 825, removed: 2)\n",
      "\n",
      "Full text:\n",
      "  PDF - 67157 json (new: 120, removed: 1050)\n",
      "  PMC - 50801 json (new: 794)\n",
      "\n",
      "---------------------------\n",
      "2020-06-07\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 136583\n",
      "CORD UIDs (new: 434, removed: 0)\n",
      "\n",
      "Full text:\n",
      "  PDF - 68087 json (new: 664, removed: 730)\n",
      "  PMC - 50007 json (new: 5)\n",
      "\n",
      "---------------------------\n",
      "2020-06-06\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 136136\n",
      "CORD UIDs (new: 60, removed: 7)\n",
      "\n",
      "Full text:\n",
      "  PDF - 68152 json (new: 681, removed: 1658)\n",
      "  PMC - 50002 json (new: 191, removed: 5)\n",
      "\n",
      "---------------------------\n",
      "2020-06-05\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 136082\n",
      "CORD UIDs (new: 281, removed: 2)\n",
      "\n",
      "Full text:\n",
      "  PDF - 69128 json (new: 753, removed: 537)\n",
      "  PMC - 49816 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-06-04\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 135803\n",
      "CORD UIDs (new: 647, removed: 8)\n",
      "\n",
      "Full text:\n",
      "  PDF - 68910 json (new: 3878, removed: 556)\n",
      "  PMC - 49816 json (new: 1130)\n",
      "\n",
      "---------------------------\n",
      "2020-06-03\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 135149\n",
      "CORD UIDs (new: 1364, removed: 6895)\n",
      "\n",
      "Full text:\n",
      "  PDF - 65587 json (new: 560, removed: 221)\n",
      "  PMC - 48686 json (new: 0, removed: 1)\n",
      "\n",
      "---------------------------\n",
      "2020-06-02\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 141109\n",
      "CORD UIDs (new: 559, removed: 5)\n",
      "\n",
      "Full text:\n",
      "  PDF - 65339 json (new: 473, removed: 1014)\n",
      "  PMC - 48687 json (new: 536)\n",
      "\n",
      "---------------------------\n",
      "2020-06-01\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 140532\n",
      "CORD UIDs (new: 601, removed: 36)\n",
      "\n",
      "Full text:\n",
      "  PDF - 65893 json (new: 975, removed: 311)\n",
      "  PMC - 48151 json (new: 488)\n",
      "\n",
      "---------------------------\n",
      "2020-05-31\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 139952\n",
      "CORD UIDs (new: 939, removed: 16)\n",
      "\n",
      "Full text:\n",
      "  PDF - 65222 json (new: 473, removed: 2716)\n",
      "  PMC - 47663 json (new: 1, removed: 62)\n",
      "\n",
      "---------------------------\n",
      "2020-05-30\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 139061\n",
      "CORD UIDs (new: 265, removed: 4)\n",
      "\n",
      "Full text:\n",
      "  PDF - 67509 json (new: 2876, removed: 364)\n",
      "  PMC - 47724 json (new: 563)\n",
      "\n",
      "---------------------------\n",
      "2020-05-29\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 138807\n",
      "CORD UIDs (new: 1447, removed: 11)\n",
      "\n",
      "Full text:\n",
      "  PDF - 64938 json (new: 822, removed: 1056)\n",
      "  PMC - 47161 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-05-28\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 137326\n",
      "CORD UIDs (new: 1247, removed: 24)\n",
      "\n",
      "Full text:\n",
      "  PDF - 65223 json (new: 2794, removed: 264)\n",
      "  PMC - 47161 json (new: 278)\n",
      "\n",
      "---------------------------\n",
      "2020-05-27\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 136067\n",
      "CORD UIDs (new: 1811, removed: 36)\n",
      "\n",
      "Full text:\n",
      "  PDF - 62646 json (new: 2657, removed: 601)\n",
      "  PMC - 46883 json (new: 3141, removed: 11)\n",
      "\n",
      "---------------------------\n",
      "2020-05-26\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "No major changes.\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 134206\n",
      "CORD UIDs (new: 5317, removed: 130)\n",
      "\n",
      "Full text:\n",
      "  PDF - 60562 json (new: 1710, removed: 781)\n",
      "  PMC - 43753 json (new: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-05-19\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "Added Medline paper source\n",
      "Changed metadata column `url` to a ;-joined list\n",
      "Added Semantic Scholar paper identifier where available to metadata column `s2_id`\n",
      "\tThe s2_id can be resolved to the Semantic Scholar paper page using the API at https://api.semanticscholar.org/\n",
      "\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 128492\n",
      "CORD UIDs (new: 71901, removed: 7266)\n",
      "\n",
      "Full text:\n",
      "  PDF - 59566 json (new: 15396, removed: 7704)\n",
      "  PMC - 43753 json (new: 10259, removed: 9)\n",
      "\n",
      "---------------------------\n",
      "2020-05-12\n",
      "\n",
      "---CHANGES---\n",
      "\n",
      "NOTE: THERE ARE SIGNIFICANT BREAKING CHANGES THIS WEEK. \n",
      "      PLEASE READ CAREFULLY.\n",
      "\n",
      "* moving to one single full text release file (document_parses.tar.gz) \n",
      "  that combines the json parses from all *.tar.gz files from \n",
      "  previous releases \n",
      "* consolidated metadata columns `has_pdf_parse` and `full_text_file` \n",
      "  into column `pdf_json_files`, which now stores the relative paths to the\n",
      "  corresponding *.json files. note: this column is a ';' separated list of \n",
      "  paths (some rows have multiple associated pdf parses).  \n",
      "  e.g. document_parses/pdf_json/e3d0d482ebd9a8ba81c254cc433f314142e72174.json\n",
      "* consolidated metadata columns `has_pmc_xml_parse`, `full_text_file` and\n",
      "  pmcid lookup into column `pmc_json_files`, which now stores the relative\n",
      "  paths to the corresponding *.xml.json files.\n",
      "  e.g. document_parses/pmc_json/PMC125375.xml.json\n",
      "* renamed metadata columns: \n",
      "    \"Microsoft Academic Paper ID\" -> \"mag_id\"\n",
      "    \"WHO #Covidence\" -> \"who_covidence_id\"\n",
      "* added HTML table parses for many files; these are in the PDF json parses \n",
      "  where available, under key \"ref_entries\", type \"table\", key \"html\". this \n",
      "  rollout is incremental, and more tables will be added as they become \n",
      "  available.\n",
      "  \n",
      "SEE FAQ FOR DETAILED INFORMATION: \n",
      "https://discourse.cord-19.semanticscholar.org/t/faqs-about-cord-19-dataset/94\n",
      " \n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 63571\n",
      "CORD UIDs (new: 3691, removed: 15)\n",
      "\n",
      "Full text:\n",
      "  PDF - 51882 json (new: 4950, removed: 1492)\n",
      "  PMC - 33503 json (new: 13989, removed: 3337)\n",
      "\n",
      "---------------------------\n",
      "2020-05-01\n",
      "\n",
      "---CHANGES---\n",
      "* added arXiv as a source of papers\n",
      "* added column arxiv_id in metadata.csv file to store arxiv identifiers\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 59887\n",
      "59851 CORD UIDs (new: 2522, removed: 4)\n",
      "\n",
      "arxiv:\n",
      "  PDF - 787 full text (new: 787)\n",
      "biorxiv_medrxiv:\n",
      "  PDF - 2670 full text (new: 543, removed: 151)\n",
      "comm_use_subset:\n",
      "  PDF - 9918 full text (new: 183, removed: 34)\n",
      "  PMC - 9540 full text (new: 171, removed: 21)\n",
      "custom_license:\n",
      "  PDF - 32450 full text (new: 1295, removed: 221)\n",
      "  PMC - 11000 full text (new: 430, removed: 45)\n",
      "noncomm_use_subset:\n",
      "  PDF - 2584 full text (new: 79, removed: 13)\n",
      "  PMC - 2311 full text (new: 61, removed: 8)\n",
      "\n",
      "---------------------------\n",
      "2020-04-24\n",
      "\n",
      "---CHANGES---\n",
      "* no changes\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 57366\n",
      "57332 CORD UIDs (new: 4988, removed: 22)\n",
      "\n",
      "biorxiv_medrxiv:\n",
      "  PDF - 2278 full text (new: 492, removed: 148)\n",
      "comm_use_subset:\n",
      "  PDF - 9769 full text (new: 253, removed: 41)\n",
      "  PMC - 9390 full text (new: 233, removed: 32)\n",
      "custom_license:\n",
      "  PDF - 31376 full text (new: 4355, removed: 199)\n",
      "  PMC - 10615 full text (new: 2630, removed: 33)\n",
      "noncomm_use_subset:\n",
      "  PDF - 2518 full text (new: 68, removed: 16)\n",
      "  PMC - 2258 full text (new: 56, removed: 10)\n",
      "\n",
      "---------------------------\n",
      "2020-04-17\n",
      "\n",
      "---CHANGES---\n",
      "* no changes\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 52398\n",
      "52365 CORD UIDs (new: 1320, removed: 1)\n",
      "\n",
      "biorxiv_medrxiv:\n",
      "  PDF - 1934 full text (new: 426, removed: 117)\n",
      "comm_use_subset:\n",
      "  PDF - 9557 full text (new: 104, removed: 71)\n",
      "  PMC - 9189 full text (new: 97, removed: 56)\n",
      "custom_license:\n",
      "  PDF - 27220 full text (new: 882, removed: 167)\n",
      "  PMC - 8018 full text (new: 224, removed: 8)\n",
      "noncomm_use_subset:\n",
      "  PDF - 2466 full text (new: 23, removed: 47)\n",
      "  PMC - 2212 full text (new: 22, removed: 27)\n",
      "\n",
      "---------------------------\n",
      "2020-04-10\n",
      "\n",
      "---CHANGES---\n",
      "* minor change to metadata deduplication logic\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 51078\n",
      "51045 CORD UIDs (new: 3786, removed: 38)\n",
      "\n",
      "biorxiv_medrxiv:\n",
      "  PDF - 1625 full text (new: 353, removed: 70)\n",
      "comm_use_subset:\n",
      "  PDF - 9524 full text (new: 174, removed: 15)\n",
      "  PMC - 9148 full text (new: 174, removed: 21)\n",
      "custom_license:\n",
      "  PDF - 26505 full text (new: 3647, removed: 294)\n",
      "  PMC - 7802 full text (new: 3081, removed: 52)\n",
      "noncomm_use_subset:\n",
      "  PDF - 2490 full text (new: 130, removed: 17)\n",
      "  PMC - 2217 full text (new: 128, removed: 4)\n",
      "\n",
      "---------------------------\n",
      "2020-04-03\n",
      "\n",
      "---CHANGES---\n",
      "* added PMC XML parses; available under metadata file column \"has_pmc_xml_parse\"\n",
      "* renamed \"has_full_text\" metadata column to \"has_pdf_parse\"\n",
      "* restructured tar.gz outputs, example new directory structure:\n",
      "|-- comm_use_subset\n",
      "   |-- pmc_json (contains all JSON derived from PMC XML parses; filenames are PMC_ID.xml.json)\n",
      "   |-- pdf_json (contains all JSON derived from PDF parses)\n",
      "\n",
      "NOTE: some papers have both PMC XML and PDF parses\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 47298\n",
      "47296 CORD UIDs (new: 1524, removed: 2)\n",
      "\n",
      "biorxiv_medrxiv:\n",
      "  PDF - 1342 full text (new: 348, removed: 59)\n",
      "comm_use_subset:\n",
      "  PDF - 9365 full text (new: 70, removed: 20)\n",
      "  PMC - 8995 full text (new: 8995, removed: 0)\n",
      "custom_license:\n",
      "  PDF - 23152 full text (new: 2541, removed: 46)\n",
      "  PMC - 4773 full text (new: 4773, removed: 0)\n",
      "noncomm_use_subset:\n",
      "  PDF - 2377 full text (new: 54, removed: 27)\n",
      "  PMC - 2093 full text (new: 2093, removed: 0)\n",
      "\n",
      "---------------------------\n",
      "2020-03-27\n",
      "\n",
      "---CHANGES---\n",
      "* added column \"cord_uid\" to metadata file (this persistent identifier is a 8-char alphanumeric string unique to each entry)\n",
      "* added column \"url\" to metadata file (URL to paper landing page where available, usually DOI/PMC/Pubmed URL)\n",
      "* normalized publication date, DOIs\n",
      "* adjusted deduplication logic slightly (affects 3 papers)\n",
      "* removed some entries that correspond to indices or table of contents\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 45774\n",
      "biorxiv_medrxiv: 1053 full text (new: 194, removed: 26)\n",
      "comm_use_subset: 9315 full text (new: 210, removed: 13)\n",
      "custom_license: 20657 full text (new: 4218, removed: 520)\n",
      "noncomm_use_subset: 2350 full text (new: 6, removed: 9)\n",
      "\n",
      "---------------------------\n",
      "2020-03-20\n",
      "\n",
      "---CHANGES---\n",
      "* normalized doi, authors, title, abstract strings\n",
      "* merged redundant rows in metadata file on doi, pmcid, and pubmed_id\n",
      "* metadata sha column can now include multiple files (some PMC files have multiple associated PDFs)\n",
      "* added column in metadata file \"full_text_file\" to signal the tar.gz file in which the full text json resides\n",
      "\n",
      "---SUMMARY---\n",
      "total metadata rows: 44220\n",
      "biorxiv_medrxiv: 885 full text (new: 110)\n",
      "comm_use_subset: 9118 full text (new: 128)\n",
      "custom_license: 16959 full text (new: 15533)\n",
      "noncomm_use_subset: 2353 full text (new: 385)\n",
      "\n",
      "\n",
      "---------------------------\n",
      "2020-03-13\n",
      "\n",
      "\n",
      "(1) Metadata for papers from these sources are combined: CZI, PMC, BioRxiv/MedRxiv. (total records 29500)\n",
      "\t- CZI 1236 records\n",
      "\t- PMC 27337\n",
      "\t- bioRxiv 566\n",
      "\t- medRxiv 361\n",
      "(2) 17K of the paper records have PDFs and the hash of the PDFs are in 'sha'\n",
      "(3) For PMC sourced papers, one paper's metadata can be associated with one or more PDFs/shas under that paper - a PDF/sha correponding to the main article, and possibly additional PDF/shas corresponding to supporting materials for the article.\n",
      "(4)\t13K of the PDFs were processed with fulltext ('has_full_text'=True)\n",
      "(5) Various 'keys' are populated with the metadata:\n",
      "\t- 'pmcid': populated for all PMC paper records (27337 non null)\n",
      "\t- 'doi': populated for all BioRxiv/MedRxiv paper records and most of the other records (26357 non null)\n",
      "\t- 'WHO #Covidence': populated for all CZI records and none of the other records (1236 non null)\n",
      "\t- 'pubmed_id': populated for some of the records\n",
      "\t- 'Microsoft Academic Paper ID': populated for some of the records\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Number of articles retrieved from biorxiv: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['abstract', 'we', 'model', 'the', 'extent', 'to', 'which', 'age', 'targeted', 'quarantine', 'can', 'be', 'used', 'to', 'reduce', 'icu', 'admissions', 'caused', 'by', 'novel', 'coronavirus', 'covid', 'using', 'demographic', 'data', 'from', 'new', 'zealand', 'we', 'demonstrate', 'that', 'lowering', 'the', 'age', 'threshold', 'for', 'quarantine', 'to', 'years', 'of', 'age', 'reduces', 'icu', 'admissions', 'drastically', 'and', 'show', 'that', 'for', 'sufficiently', 'strict', 'isolation', 'protocols', 'isolating', 'one', 'third', 'of', 'the', 'countries', 'population', 'for', 'total', 'of', 'months', 'is', 'sufficient', 'to', 'avoid', 'overwhelming', 'icu', 'capacity', 'throughout', 'the', 'entire', 'course', 'of', 'the', 'epidemic', 'similar', 'results', 'are', 'expected', 'to', 'hold', 'for', 'other', 'countries', 'though', 'some', 'minor', 'adaption', 'will', 'be', 'required', 'based', 'on', 'local', 'age', 'demographics', 'and', 'hospital', 'facilities', 'cc', 'by', 'international', 'license', 'it', 'is', 'made', 'available', 'under', 'author', 'funder', 'who', 'has', 'granted', 'medrxiv', 'license', 'to', 'display', 'the', 'preprint', 'in', 'perpetuity', 'is', 'the', 'which', 'was', 'not', 'peer', 'reviewed', 'the', 'copyright', 'holder', 'for', 'this', 'preprint']]\n",
      "['abstract', 'during', 'the', 'current_covid_pandemic', 'testing', 'kit', 'and', 'rna_extraction', 'kit', 'availability', 'has_become', 'major', 'limiting', 'factor', 'in', 'the', 'ability', 'to', 'determine', 'patient', 'disease', 'status', 'and', 'accurately', 'quantify', 'prevalence', 'current', 'testing', 'strategies', 'rely_on', 'individual', 'tests', 'of', 'cases', 'matching', 'restrictive', 'diagnostic', 'criteria', 'to', 'detect', 'sars_cov', 'rna', 'limiting', 'testing', 'of', 'asymptomatic', 'and', 'mild_cases', 'testing', 'these', 'individuals', 'is', 'one', 'effective', 'way', 'to', 'understand', 'and', 'reduce', 'the', 'spread', 'of', 'covid', 'here_we', 'develop', 'pooled', 'testing', 'strategy', 'to', 'identify', 'these', 'low', 'risk', 'individuals', 'drawing', 'on', 'the', 'well_studied', 'group', 'testing', 'literature', 'modeling', 'suggests', 'practical', 'changes', 'to', 'testing', 'protocols', 'which', 'can', 'reduce', 'test', 'costs', 'and', 'stretch', 'limited', 'test_kit', 'supply', 'when', 'most', 'tests', 'are', 'negative', 'pooling', 'reduces', 'the', 'total_number', 'of', 'tests', 'up', 'to', 'four', 'fold', 'at', 'prevalence', 'and', 'eight', 'fold', 'at', 'prevalence', 'at', 'current', 'sars_cov', 'prevalence', 'randomized', 'group', 'testing', 'optimized', 'per', 'country', 'could', 'double', 'the', 'number', 'of', 'tested', 'individuals', 'from', 'to', 'using', 'only', 'more', 'tests', 'this', 'strategy', 'is', 'well_suited', 'to', 'supplement', 'testing', 'for', 'asymptomatic', 'and', 'mild_cases', 'who', 'would', 'otherwise', 'go', 'untested', 'and', 'enable', 'them', 'to', 'adopt', 'behavioral_changes', 'to', 'slow', 'the', 'spread', 'of', 'covid']\n",
      "['abstract', 'current', 'covid_pandemic', 'testing', 'kit', 'kit', 'availability', 'become', 'major', 'limit', 'factor', 'ability', 'determine', 'patient', 'disease', 'status', 'accurately', 'quantify', 'prevalence', 'current', 'testing', 'strategy', 'rely', 'individual', 'test', 'case', 'match', 'restrictive', 'diagnostic', 'criterion', 'detect', 'limit', 'test', 'asymptomatic', 'mild', 'case', 'test', 'individual', 'effective', 'way', 'understand', 'reduce', 'spread', 'covid', 'develop', 'pool', 'testing', 'strategy', 'identify', 'low', 'risk', 'individual', 'draw', 'well', 'studied', 'group', 'testing', 'literature', 'modeling', 'suggest', 'practical', 'change', 'testing', 'protocol', 'reduce', 'test', 'cost', 'stretch', 'limited', 'test_kit', 'supply', 'test', 'negative', 'pooling', 'reduce', 'test', 'fold', 'prevalence', 'fold', 'prevalence', 'current', 'prevalence', 'randomize', 'group', 'testing', 'optimize', 'country', 'could', 'double', 'number', 'test', 'individual', 'use', 'test', 'strategy', 'well_suite', 'supplement', 'testing', 'asymptomatic', 'mild', 'case', 'would', 'otherwise', 'go', 'untested', 'enable', 'slow', 'spread', 'covid']\n",
      "[['model', 'extent', 'age', 'target', 'quarantine', 'use', 'reduce', 'cause', 'covid', 'use', 'demographic', 'datum', 'demonstrate', 'lower', 'age', 'threshold', 'quarantine', 'year', 'age', 'reduce', 'drastically', 'show', 'sufficiently', 'strict', 'isolation', 'protocol', 'isolate', 'third', 'country', 'population', 'total', 'month', 'sufficient', 'avoid', 'overwhelm', 'entire', 'course', 'epidemic', 'similar', 'expect', 'hold', 'country', 'minor', 'adaption', 'require', 'base', 'local', 'age', 'demographic', 'hospital', 'facility', 'cc', 'license', 'display', 'preprint', 'preprint']]\n",
      "[[(0, 1), (1, 4), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 2), (32, 1), (33, 2), (34, 2), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 2), (46, 1)]]\n",
      "\n",
      "Perplexity:  -7.8859062174873165\n",
      "\n",
      "Coherence Score:  0.4434890289777442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from PIL import PILLOW_VERSION\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "n = 1000\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "\n",
    "import bert\n",
    "\n",
    "import itertools\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "import nltk\n",
    "### To install nltk take out comments from next few lines\n",
    "\n",
    "#import ssl\n",
    "\n",
    "#try:\n",
    "#   _create_unverified_https_context = ssl._create_unverified_context\n",
    "#except AttributeError:\n",
    "#   pass\n",
    "#else:\n",
    "#   ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "#nltk.download()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['background', 'methods', 'introduction', 'conclusions', 'results',\n",
    "                   'purpose', 'materials', 'discussions','methodology','result analysis'])\n",
    "# %% Reading Directory\n",
    "\n",
    "# os.listdir('../Users/raghavkhandelwal/PycharmProjects/Stanford/CORD19_CS_221/CORD-19/')\n",
    "os.listdir(os.path.expanduser('~/Downloads/CORD19/'))\n",
    "\n",
    "with open(os.path.expanduser('~/Downloads/CORD19/metadata.readme')) as f:\n",
    "    data = f.read()\n",
    "    print(data)\n",
    "\n",
    "\n",
    "biorxiv_dir = os.listdir(os.path.expanduser('~/Downloads/CORD19/biorxiv_medrxiv/'))\n",
    "print(\"Number of articles retrieved from biorxiv:\", len(biorxiv_dir))\n",
    "\n",
    "\n",
    "biorxiv_clean = pd.read_csv(os.path.expanduser('~/Downloads/CORD19/biorxiv_clean.csv'))\n",
    "clean_comm_use = pd.read_csv(os.path.expanduser('~/Downloads/CORD19/clean_comm_use.csv'))\n",
    "clean_noncomm_use =  pd.read_csv(os.path.expanduser('~/Downloads/CORD19/clean_noncomm_use.csv'))\n",
    "clean_pmc =  pd.read_csv(os.path.expanduser('~/Downloads/CORD19/clean_pmc.csv'))\n",
    "\n",
    "biorxiv_clean.head(2)\n",
    "clean_comm_use.head(2)\n",
    "clean_noncomm_use.head(2)\n",
    "clean_pmc.head(2)\n",
    "biorxiv_clean.text[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "#https://www.kaggle.com/gpreda/cord-19-solution-toolbox\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=200,\n",
    "        max_font_size=30,\n",
    "        scale=5,\n",
    "        random_state=1\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(10,10))\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "show_wordcloud(biorxiv_clean['abstract'], title = 'biorxiv_clean - papers Abstract - frequent words (400 sample)')\n",
    "\n",
    "df = biorxiv_clean\n",
    "df = df.abstract.dropna()\n",
    "data = df.values.tolist()\n",
    "\n",
    "# *I have downloaded simsentence.csv from version 1's output of this kernel and now using that csv file in cell below for little analysis *\n",
    "simsentence = pd.read_csv(os.path.expanduser('~/Downloads/CORD19//simsentence.csv'))\n",
    "\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])\n",
    "\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=20) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=20)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[1]]])\n",
    "\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#or\n",
    "#spacy.cli.download(\"en\")\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[1])\n",
    "\n",
    "print(data_lemmatized[:1])\n",
    "\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n",
    "\n",
    "# Topic Modeling\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True\n",
    "                                        )\n",
    "\n",
    "#pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]\n",
    "\n",
    "# Computing proplexity and coherence score\n",
    "\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis\n",
    "\n",
    "pyLDAvis.save_html(vis, './lda4topics_v2.html')\n",
    "\n",
    "\n",
    "optimal_model = lda_model\n",
    "\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=100,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False,\n",
    "                               num_words=30)\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=(10,20), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=500)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i + 1), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def sentences_chart(lda_model=lda_model, corpus=corpus, start = 0, end = 12):\n",
    "    corp = corpus[start:end]\n",
    "    mycolors = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "\n",
    "    fig, axes = plt.subplots(end-start, 1, figsize=(22, 10))\n",
    "    axes[0].axis('off')\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i > 1:\n",
    "            #i = i+1\n",
    "            corp_cur = corp[i-1]\n",
    "            topic_percs, wordid_topics, wordid_phivalues = lda_model[corp_cur]\n",
    "            word_dominanttopic = [(lda_model.id2word[wd], topic[0]) for wd, topic in wordid_topics]\n",
    "            ax.text(0.01, 0.5, \"Doc \" + str(i-1) + \": \", verticalalignment='center',\n",
    "                    fontsize=15, color='black', transform=ax.transAxes, fontweight=700)\n",
    "\n",
    "            # Draw Rectange\n",
    "            topic_percs_sorted = sorted(topic_percs, key=lambda x: (x[1]), reverse=True)\n",
    "            ax.add_patch(Rectangle((0.0, 0.05), 0.99, 0.90, fill=None, alpha=1,\n",
    "                                   color=mycolors[topic_percs_sorted[0][0]], linewidth=2))\n",
    "\n",
    "            word_pos = 0.06\n",
    "            for j, (word, topics) in enumerate(word_dominanttopic):\n",
    "                if j < 14:\n",
    "                    ax.text(word_pos, 0.5, word,\n",
    "                            horizontalalignment='left',\n",
    "                            verticalalignment='center',\n",
    "                            fontsize=16, color=mycolors[topics],\n",
    "                            transform=ax.transAxes, fontweight=700)\n",
    "                    word_pos += 0.009 * len(word)  # to move the word for the next iter\n",
    "                    ax.axis('off')\n",
    "            ax.text(word_pos, 0.5, '. . .',\n",
    "                    horizontalalignment='left',\n",
    "                    verticalalignment='center',\n",
    "                    fontsize=16, color='black',\n",
    "                    transform=ax.transAxes)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.suptitle('Sentence Topic Coloring for Documents: ' + str(start) + ' to ' + str(end-2), fontsize=20, x = 0.2, y=0.95, fontweight=700)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "sentences_chart()\n",
    "\n",
    "corp = corpus[0:13]\n",
    "corp_cur = corp[13-1]\n",
    "topic_percs, wordid_topics, wordid_phivalues = lda_model[corp_cur]\n",
    "word_dominanttopic = [(lda_model.id2word[wd], topic[0]) for wd, topic in wordid_topics]\n",
    "word_dominanttopic\n",
    "\n",
    "def topics_per_document(model, corpus, start=0, end=1):\n",
    "    corpus_sel = corpus[start:end]\n",
    "    dominant_topics = []\n",
    "    topic_percentages = []\n",
    "    for i, corp in enumerate(corpus_sel):\n",
    "        topic_percs, wordid_topics, wordid_phivalues = model[corp]\n",
    "        dominant_topic = sorted(topic_percs, key = lambda x: x[1], reverse=True)[0][0]\n",
    "        dominant_topics.append((i, dominant_topic))\n",
    "        topic_percentages.append(topic_percs)\n",
    "    return(dominant_topics, topic_percentages)\n",
    "\n",
    "dominant_topics, topic_percentages = topics_per_document(model=lda_model, corpus=corpus, end=-1)\n",
    "\n",
    "# Distribution of Dominant Topics in Each Document\n",
    "df = pd.DataFrame(dominant_topics, columns=['Document_Id', 'Dominant_Topic'])\n",
    "dominant_topic_in_each_doc = df.groupby('Dominant_Topic').size()\n",
    "df_dominant_topic_in_each_doc = dominant_topic_in_each_doc.to_frame(name='count').reset_index()\n",
    "\n",
    "# Total Topic Distribution by actual weight\n",
    "topic_weightage_by_doc = pd.DataFrame([dict(t) for t in topic_percentages])\n",
    "df_topic_weightage_by_doc = topic_weightage_by_doc.sum().to_frame(name='count').reset_index()\n",
    "\n",
    "# Top 3 Keywords for each Topic\n",
    "topic_top3words = [(i, topic) for i, topics in lda_model.show_topics(formatted=False)\n",
    "                                 for j, (topic, wt) in enumerate(topics) if j < 3]\n",
    "\n",
    "df_top3words_stacked = pd.DataFrame(topic_top3words, columns=['topic_id', 'words'])\n",
    "df_top3words = df_top3words_stacked.groupby('topic_id').agg(', \\n'.join)\n",
    "df_top3words.reset_index(level=0,inplace=True)\n",
    "\n",
    "\n",
    "import bokeh\n",
    "from bokeh.models import HoverTool\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Get topic weights\n",
    "topic_weights = []\n",
    "for i, row_list in enumerate(lda_model[corpus]):\n",
    "    topic_weights.append([w for i, w in row_list[0]])\n",
    "\n",
    "# Array of topic weights\n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "n_topics = 5\n",
    "mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "\n",
    "\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics),\n",
    "              plot_width=800, plot_height=600)\n",
    "plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "show(plot)\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n",
    "    # # Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "    # # Run in terminal: python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "    # # Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:2])\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Plot\n",
    "\n",
    "fig, ax1  = plt.subplots(1, figsize=(10, 10))\n",
    "\n",
    "# Topic Distribution by Dominant Topics\n",
    "ax1.bar(x='Dominant_Topic', height='count', data=df_dominant_topic_in_each_doc, width=.5, color='firebrick')\n",
    "ax1.set_xticks(range(df_dominant_topic_in_each_doc.Dominant_Topic.unique().__len__()))\n",
    "tick_formatter = FuncFormatter(lambda x, pos: 'Topic ' + str(x + 1)+ ':\\n' + df_top3words.loc[df_top3words.topic_id==x, 'words'].values[0])\n",
    "ax1.xaxis.set_major_formatter(tick_formatter)\n",
    "ax1.set_title('Number of Documents by Dominant Topic', fontdict=dict(size=10))\n",
    "ax1.set_ylabel('Number of Documents')\n",
    "ax1.set_ylim(0, 2000)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "df_dominant_topic_in_each_doc\n",
    "\n",
    "fig, ax2  = plt.subplots(1, figsize=(10, 10))\n",
    "# Topic Distribution by Topic Weights\n",
    "ax2.bar(x='index', height='count', data=df_topic_weightage_by_doc, width=.5, color='steelblue')\n",
    "ax2.set_xticks(range(df_topic_weightage_by_doc.index.unique().__len__()))\n",
    "ax2.xaxis.set_major_formatter(tick_formatter)\n",
    "ax2.set_title('Number of Documents by Topic Weightage', fontdict=dict(size=10))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', min_df=10,                        # minimum reqd occurences of a word\n",
    "                              stop_words='english',             # remove stop words\n",
    "                              lowercase=True,                   # convert all words to lowercase\n",
    "                              token_pattern='[a-zA-Z0-9]{3,}'  # num chars > 3\n",
    "                              # max_features=50000,             # max number of uniq words\n",
    "                             )\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)\n",
    "\n",
    "search_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation(n_jobs=-1)\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)\n",
    "\n",
    "\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))\n",
    "\n",
    "categories = list(df.Dominant_Topic.unique())\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df1 = clean_comm_use\n",
    "df1 = df1.dropna()\n",
    "\n",
    "words = []\n",
    "for ii in range(0,len(df1)):\n",
    "    words.append(str(df1.iloc[ii]['text']).split(\" \"))\n",
    "    \n",
    "    \n",
    "n_gram_all = []\n",
    "\n",
    "for word in words:\n",
    "    # get n-grams for the instance\n",
    "    n_gram = []\n",
    "    for i in range(len(word)-2+1):\n",
    "        n_gram.append(\"\".join(word[i:i+2]))\n",
    "    n_gram_all.append(n_gram)\n",
    "    \n",
    "    from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# hash vectorizer instance\n",
    "hvec = HashingVectorizer(lowercase=False, analyzer=lambda l:l, n_features=2**12)\n",
    "\n",
    "# features matrix X\n",
    "X = hvec.fit_transform(n_gram_all)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test set size of 20% of the data and the random seed 42 <3\n",
    "X_train, X_test = train_test_split(X.toarray(), test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train size:\", len(X_train))\n",
    "print(\"X_test size:\", len(X_test), \"\\n\")\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 15 \n",
    "kmeans = KMeans(n_clusters=k, n_jobs=4, verbose= k)\n",
    "y_pred = kmeans.fit_predict(X_train)\n",
    "\n",
    "y_pred.shape\n",
    "\n",
    "y_train = y_pred\n",
    "y_test = kmeans.predict(X_test)\n",
    "\n",
    "%%time\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(verbose=1)\n",
    "X_embedded = tsne.fit_transform(X_train)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sns settings\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "\n",
    "# colors\n",
    "palette = sns.color_palette(\"bright\", 1)\n",
    "\n",
    "# plot\n",
    "sns.scatterplot(X_embedded[:,0], X_embedded[:,1], palette=palette)\n",
    "\n",
    "plt.title(\"t-SNE Covid-19 Articles\")\n",
    "# plt.savefig(\"plots/t-sne_covid19.png\")\n",
    "plt.show()\n",
    "\n",
    "X_embedded[:,1].shape\n",
    "\n",
    "# sns settings\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "\n",
    "# colors\n",
    "palette = sns.color_palette(\"bright\", len(set(y_pred)))\n",
    "\n",
    "# plot\n",
    "sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_pred, legend='full', palette=palette)\n",
    "plt.title(\"t-SNE Covid-19 Articles - Clustered\")\n",
    "# plt.savefig(\"plots/t-sne_covid19_label.png\")\n",
    "plt.show()\n",
    "\n",
    "type(clean_noncomm_use.abstract.dropna().tolist())\n",
    "\n",
    "from gensim.summarization.summarizer import summarize\n",
    "summarize(clean_noncomm_use.abstract.dropna().to_string())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt') # one time execution\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = []\n",
    "for s in clean_noncomm_use.abstract.dropna():\n",
    "    sentences.append(sent_tokenize(s))\n",
    "\n",
    "sentences = [y for x in sentences for y in x] # flatten list\n",
    "\n",
    "sentences[:3]\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip\n",
    "\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n",
    "\n",
    "len(word_embeddings)\n",
    "\n",
    "# remove punctuations, numbers and special characters\n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "# make alphabets lowercase\n",
    "clean_sentences = [s.lower() for s in clean_sentences]\n",
    "\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new\n",
    "\n",
    "# remove stopwords from the sentences\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
    "\n",
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n",
    "\n",
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "    if len(i) != 0:\n",
    "        v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "    else:\n",
    "        v = np.zeros((100,))\n",
    "    sentence_vectors.append(v)\n",
    "    \n",
    "    # similarity matrix\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "%%time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        if i != j:\n",
    "            sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]\n",
    "            #print(sim_mat[i][j])\n",
    "            \n",
    "            \n",
    "            %%time\n",
    "import networkx as nx\n",
    "\n",
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)\n",
    "\n",
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "for i in range(50):\n",
    "    print(ranked_sentences[i][1])\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean_pmc.title\n",
    "\n",
    "import os\n",
    "os.listdir('cased_L-12_H-768_A-12')\n",
    "BERT_VOCAB = 'cased_L-12_H-768_A-12/vocab.txt'\n",
    "BERT_INIT_CHKPNT = 'cased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "BERT_CONFIG = 'cased_L-12_H-768_A-12/bert_config.json'\n",
    "\n",
    "def generate_ngram(seq, ngram = (1, 3)):\n",
    "    g = []\n",
    "    for i in range(ngram[0], ngram[-1] + 1):\n",
    "        g.extend(list(ngrams_generator(seq, i)))\n",
    "    return g\n",
    "\n",
    "def _pad_sequence(\n",
    "    sequence,\n",
    "    n,\n",
    "    pad_left = False,\n",
    "    pad_right = False,\n",
    "    left_pad_symbol = None,\n",
    "    right_pad_symbol = None,\n",
    "):\n",
    "    sequence = iter(sequence)\n",
    "    if pad_left:\n",
    "        sequence = itertools.chain((left_pad_symbol,) * (n - 1), sequence)\n",
    "    if pad_right:\n",
    "        sequence = itertools.chain(sequence, (right_pad_symbol,) * (n - 1))\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def ngrams_generator(\n",
    "    sequence,\n",
    "    n,\n",
    "    pad_left = False,\n",
    "    pad_right = False,\n",
    "    left_pad_symbol = None,\n",
    "    right_pad_symbol = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    generate ngrams.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence : list of str\n",
    "        list of tokenize words.\n",
    "    n : int\n",
    "        ngram size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ngram: list\n",
    "    \"\"\"\n",
    "    sequence = _pad_sequence(\n",
    "        sequence, n, pad_left, pad_right, left_pad_symbol, right_pad_symbol\n",
    "    )\n",
    "\n",
    "    history = []\n",
    "    while n > 1:\n",
    "        try:\n",
    "            next_item = next(sequence)\n",
    "        except StopIteration:\n",
    "            return\n",
    "        history.append(next_item)\n",
    "        n -= 1\n",
    "    for item in sequence:\n",
    "        history.append(item)\n",
    "        yield tuple(history)\n",
    "        del history[0]\n",
    "\n",
    "def merge_wordpiece_tokens(paired_tokens, weighted = True):\n",
    "    new_paired_tokens = []\n",
    "    n_tokens = len(paired_tokens)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < n_tokens:\n",
    "        current_token, current_weight = paired_tokens[i]\n",
    "        if current_token.startswith('##'):\n",
    "            previous_token, previous_weight = new_paired_tokens.pop()\n",
    "            merged_token = previous_token\n",
    "            merged_weight = [previous_weight]\n",
    "            while current_token.startswith('##'):\n",
    "                merged_token = merged_token + current_token.replace('##', '')\n",
    "                merged_weight.append(current_weight)\n",
    "                i = i + 1\n",
    "                current_token, current_weight = paired_tokens[i]\n",
    "            merged_weight = np.mean(merged_weight)\n",
    "            new_paired_tokens.append((merged_token, merged_weight))\n",
    "\n",
    "        else:\n",
    "            new_paired_tokens.append((current_token, current_weight))\n",
    "            i = i + 1\n",
    "\n",
    "    words = [\n",
    "        i[0]\n",
    "        for i in new_paired_tokens\n",
    "        if i[0] not in ['[CLS]', '[SEP]', '[PAD]']\n",
    "    ]\n",
    "    weights = [\n",
    "        i[1]\n",
    "        for i in new_paired_tokens\n",
    "        if i[0] not in ['[CLS]', '[SEP]', '[PAD]']\n",
    "    ]\n",
    "    if weighted:\n",
    "        weights = np.array(weights)\n",
    "        weights = weights / np.sum(weights)\n",
    "    return list(zip(words, weights))\n",
    "\n",
    "def _extract_attention_weights(num_layers, tf_graph):\n",
    "    attns = [\n",
    "        {\n",
    "            'layer_%s'\n",
    "            % i: tf_graph.get_tensor_by_name(\n",
    "                'bert/encoder/layer_%s/attention/self/Softmax:0' % i\n",
    "            )\n",
    "        }\n",
    "        for i in range(num_layers)\n",
    "    ]\n",
    "\n",
    "    return attns\n",
    "\n",
    "\n",
    "from bert import modeling \n",
    "\n",
    "def padding_sequence(seq, maxlen, padding = 'post', pad_int = 0):\n",
    "    padded_seqs = []\n",
    "    for s in seq:\n",
    "        if padding == 'post':\n",
    "            padded_seqs.append(s + [pad_int] * (maxlen - len(s)))\n",
    "        if padding == 'pre':\n",
    "            padded_seqs.append([pad_int] * (maxlen - len(s)) + s)\n",
    "    return padded_seqs\n",
    "\n",
    "\n",
    "def bert_tokenization(tokenizer, texts, cls = '[CLS]', sep = '[SEP]'):\n",
    "\n",
    "    input_ids, input_masks, segment_ids, s_tokens = [], [], [], []\n",
    "    for text in texts:\n",
    "        tokens_a = tokenizer.tokenize(text)\n",
    "        tokens = [cls] + tokens_a + [sep]\n",
    "        segment_id = [0] * len(tokens)\n",
    "        input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_id)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        s_tokens.append(tokens)\n",
    "\n",
    "    maxlen = max([len(i) for i in input_ids])\n",
    "    input_ids = padding_sequence(input_ids, maxlen)\n",
    "    input_masks = padding_sequence(input_masks, maxlen)\n",
    "    segment_ids = padding_sequence(segment_ids, maxlen)\n",
    "\n",
    "    return input_ids, input_masks, segment_ids, s_tokens\n",
    "\n",
    "class _Model:\n",
    "    def __init__(self, bert_config, tokenizer):\n",
    "        _graph = tf.Graph()\n",
    "        with _graph.as_default():\n",
    "            self.X = tf.placeholder(tf.int32, [None, None])\n",
    "            self._tokenizer = tokenizer\n",
    "\n",
    "            self.model = modeling.BertModel(\n",
    "                config = bert_config,\n",
    "                is_training = False,\n",
    "                input_ids = self.X,\n",
    "                use_one_hot_embeddings = False,\n",
    "            )\n",
    "            self.logits = self.model.get_pooled_output()\n",
    "            self._sess = tf.InteractiveSession()\n",
    "            self._sess.run(tf.global_variables_initializer())\n",
    "            var_lists = tf.get_collection(\n",
    "                tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'bert'\n",
    "            )\n",
    "            self._saver = tf.train.Saver(var_list = var_lists)\n",
    "            attns = _extract_attention_weights(\n",
    "                bert_config.num_hidden_layers, tf.get_default_graph()\n",
    "            )\n",
    "            self.attns = attns\n",
    "\n",
    "    def vectorize(self, strings):\n",
    "\n",
    "        \"\"\"\n",
    "        Vectorize string inputs using bert attention.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        strings : str / list of str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array: vectorized strings\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(strings, list):\n",
    "            if not isinstance(strings[0], str):\n",
    "                raise ValueError('input must be a list of strings or a string')\n",
    "        else:\n",
    "            if not isinstance(strings, str):\n",
    "                raise ValueError('input must be a list of strings or a string')\n",
    "        if isinstance(strings, str):\n",
    "            strings = [strings]\n",
    "\n",
    "        batch_x, _, _, _ = bert_tokenization(self._tokenizer, strings)\n",
    "        return self._sess.run(self.logits, feed_dict = {self.X: batch_x})\n",
    "\n",
    "    def attention(self, strings, method = 'last', **kwargs):\n",
    "        \"\"\"\n",
    "        Get attention string inputs from bert attention.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        strings : str / list of str\n",
    "        method : str, optional (default='last')\n",
    "            Attention layer supported. Allowed values:\n",
    "\n",
    "            * ``'last'`` - attention from last layer.\n",
    "            * ``'first'`` - attention from first layer.\n",
    "            * ``'mean'`` - average attentions from all layers.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array: attention\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(strings, list):\n",
    "            if not isinstance(strings[0], str):\n",
    "                raise ValueError('input must be a list of strings or a string')\n",
    "        else:\n",
    "            if not isinstance(strings, str):\n",
    "                raise ValueError('input must be a list of strings or a string')\n",
    "        if isinstance(strings, str):\n",
    "            strings = [strings]\n",
    "\n",
    "        method = method.lower()\n",
    "        if method not in ['last', 'first', 'mean']:\n",
    "            raise Exception(\n",
    "                \"method not supported, only support 'last', 'first' and 'mean'\"\n",
    "            )\n",
    "\n",
    "        batch_x, _, _, s_tokens = bert_tokenization(self._tokenizer, strings)\n",
    "        maxlen = max([len(s) for s in s_tokens])\n",
    "        s_tokens = padding_sequence(s_tokens, maxlen, pad_int = '[SEP]')\n",
    "        attentions = self._sess.run(self.attns, feed_dict = {self.X: batch_x})\n",
    "        if method == 'first':\n",
    "            cls_attn = list(attentions[0].values())[0][:, :, 0, :]\n",
    "\n",
    "        if method == 'last':\n",
    "            cls_attn = list(attentions[-1].values())[0][:, :, 0, :]\n",
    "\n",
    "        if method == 'mean':\n",
    "            combined_attentions = []\n",
    "            for a in attentions:\n",
    "                combined_attentions.append(list(a.values())[0])\n",
    "            cls_attn = np.mean(combined_attentions, axis = 0).mean(axis = 2)\n",
    "\n",
    "        cls_attn = np.mean(cls_attn, axis = 1)\n",
    "        total_weights = np.sum(cls_attn, axis = -1, keepdims = True)\n",
    "        attn = cls_attn / total_weights\n",
    "        output = []\n",
    "        for i in range(attn.shape[0]):\n",
    "            output.append(\n",
    "                merge_wordpiece_tokens(list(zip(s_tokens[i], attn[i])))\n",
    "            )\n",
    "        return output\n",
    "    \n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "from bert import modeling  \n",
    "\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=BERT_VOCAB, do_lower_case=False)\n",
    "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)\n",
    "model = _Model(bert_config, tokenizer)\n",
    "\n",
    "\n",
    "v = model.vectorize(['hello nice to meet u', 'so long sucker'])\n",
    "v\n",
    "\n",
    "model.attention(['hello nice to meet u', 'so long sucker'])\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "ngram = (1, 3)\n",
    "n_topics = 10\n",
    "\n",
    "df = clean_pmc\n",
    "df = df.title.dropna()\n",
    "negative = df.values.tolist()\n",
    "negative[0]\n",
    "\n",
    "negative = negative[:100]\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "\n",
    "rows, attentions = [], []\n",
    "for i in (range (len(negative))):\n",
    "          #index = min(i + batch_size, len(negative))\n",
    "          rows.append(model.vectorize(negative[i]))\n",
    "          attentions.extend(model.attention(negative[i]))\n",
    "          \n",
    "          \n",
    "stopwords = stop_words   \n",
    "\n",
    "concat = np.concatenate(rows, axis = 0)\n",
    "kmeans = KMeans(n_clusters = n_topics, random_state = 0).fit(concat)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "overall, filtered_a = [], []\n",
    "for a in attentions:\n",
    "    #print(a)\n",
    "    f = [i for i in a if i[0] not in stopwords]\n",
    "    overall.extend(f)\n",
    "    filtered_a.append(f)\n",
    "\n",
    "o_ngram = generate_ngram(overall, ngram)\n",
    "features = []\n",
    "for i in o_ngram:\n",
    "    #print(i)\n",
    "    features.append(' '.join([w[0] for w in i]))\n",
    "features = list(set(features))\n",
    "\n",
    "components = np.zeros((n_topics, len(features)))\n",
    "print(n_topics)\n",
    "#print(features)\n",
    "for no, i in enumerate(labels):\n",
    "    if (no + 1) % 500 == 0: \n",
    "        print('processed %d'%(no + 1))\n",
    "    f = generate_ngram(filtered_a[no], ngram)\n",
    "    for w in f:\n",
    "        word = ' '.join([r[0] for r in w])\n",
    "        score = np.mean([r[1] for r in w])\n",
    "        if word in features:\n",
    "            components[i, features.index(word)] += score\n",
    "            \n",
    "def print_topics_modelling(\n",
    "    topics, feature_names, sorting, n_words = 20, return_df = True\n",
    "):\n",
    "    if return_df:\n",
    "        try:\n",
    "            import pandas as pd\n",
    "        except:\n",
    "            raise Exception(\n",
    "                'pandas not installed. Please install it and try again or set `return_df = False`'\n",
    "            )\n",
    "    df = {}\n",
    "    for i in range(topics):\n",
    "        words = []\n",
    "        for k in range(n_words):\n",
    "            words.append(feature_names[sorting[i, k]])\n",
    "        df['topic %d' % (i)] = words\n",
    "    if return_df:\n",
    "        return pd.DataFrame.from_dict(df)\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "    \n",
    "print_topics_modelling(\n",
    "    10,\n",
    "    feature_names = np.array(features),\n",
    "    sorting = np.argsort(components)[:, ::-1],\n",
    "    n_words = 10,\n",
    "    return_df = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers\n",
    "!pip install -U torch\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "\n",
    "BART_PATH = 'bart-large'\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(BART_PATH, output_past=True)\n",
    "\n",
    "bart_tokenizer = BartTokenizer.from_pretrained(BART_PATH)\n",
    "\n",
    "def bart_summarize(input_text, num_beams=4, num_words=80):\n",
    "    #input_text = str(input_text)\n",
    "    input_text = ' '.join(input_text.split())\n",
    "    input_tokenized = bart_tokenizer.encode(input_text, return_tensors='pt')\n",
    "    summary_ids = bart_model.generate(input_tokenized,\n",
    "                                      num_beams=int(num_beams),\n",
    "                                      no_repeat_ngram_size=3,\n",
    "                                      length_penalty=2.0,\n",
    "                                      min_length=100,\n",
    "                                      max_length=int(num_words),\n",
    "                                      early_stopping=True)\n",
    "    output = [bart_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "    return output[0]\n",
    "\n",
    "df = clean_pmc\n",
    "df = df.abstract.dropna()\n",
    "abstracts = df.values.tolist()\n",
    "\n",
    "len(abstracts)\n",
    "\n",
    "%%time\n",
    "for i in range(20):\n",
    "    try:\n",
    "        print('paper  ',i + 1, \" : \\n\" )\n",
    "        print(bart_summarize(abstracts[i]))\n",
    "        print('............................................................................\\n\\n\\n\\n')\n",
    "    except:\n",
    "        print('paper ',i+1 ,\" has LONG ABSTRACT\\n\\n\")\n",
    "        \n",
    "        \n",
    "df1 = biorxiv_clean\n",
    "df1 = df1.abstract.dropna()\n",
    "df1abstracts = df.values.tolist()\n",
    "\n",
    "len(df1abstracts)\n",
    "\n",
    "T5_PATH = 't5-base'\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(T5_PATH, output_past=True)\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(T5_PATH)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def t5_summarize(input_text, num_beams=4, num_words=80):\n",
    "    #input_text = str(input_text).replace('\\n', '')\n",
    "    input_text = ' '.join(input_text.split())\n",
    "    input_tokenized = t5_tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    summary_task = torch.tensor([[21603, 10]]).to(device)\n",
    "    input_tokenized = torch.cat([summary_task, input_tokenized], dim=-1).to(device)\n",
    "    summary_ids = t5_model.generate(input_tokenized,\n",
    "                                    num_beams=int(num_beams),\n",
    "                                    no_repeat_ngram_size=3,\n",
    "                                    length_penalty=2.0,\n",
    "                                    min_length=30,\n",
    "                                    max_length=int(num_words),\n",
    "                                    early_stopping=True)\n",
    "    output = [t5_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "    return output[0]\n",
    "\n",
    "\n",
    "%%time\n",
    "for i in range(20):\n",
    "    try:\n",
    "        print('BioArvix paper  ',i + 1, \" : \\n\" )\n",
    "        print(t5_summarize(df1abstracts[i]))\n",
    "        print('............................................................................\\n\\n\\n\\n')\n",
    "    except:\n",
    "        print('paper ',i+1 ,\" has LONG ABSTRACT\\n\\n\")\n",
    "\n",
    "!pip install sentence-transformers\n",
    "\"\"\"\n",
    "This is a simple application for sentence embeddings: semantic search\n",
    "We have a corpus with various sentences. Then, for a given query sentence,\n",
    "we want to find the most similar sentence in this corpus.\n",
    "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
    "\"\"\"\n",
    "# taken from : https://github.com/UKPLab/sentence-transformers/blob/master/examples/application_semantic_search.py\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "\n",
    "embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = simsentence.similar.tolist()\n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['Range of incubation periods for the disease in humans', 'antiviral covid-19 success treatment','virus detected from animals?', 'risk of fatality among symptomatic hospitalized patients']\n",
    "query_embeddings = embedder.encode(queries)\n",
    "\n",
    "# Find the closest  sentences of the corpus for each query sentence based on cosine similarity\n",
    "closest_n = 5\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n",
    "\n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences from similar\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (1-distance))\n",
    "        \n",
    "        \n",
    "\"\"\"\n",
    "This is a simple application for sentence embeddings: semantic search\n",
    "We have a corpus with various sentences. Then, for a given query sentence,\n",
    "we want to find the most similar sentence in this corpus.\n",
    "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
    "\"\"\"\n",
    "# taken from : https://github.com/UKPLab/sentence-transformers/blob/master/examples/application_semantic_search.py\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "\n",
    "embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = df.values.tolist()\n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['Range of incubation periods for the disease in humans','risk factors of covid-19','cure for covid-19', 'antiviral covid-19 success treatment','Does smoking or pre-existing pulmonary disease increase risk of COVID-19?', 'risk of fatality among symptomatic hospitalized patients']\n",
    "query_embeddings = embedder.encode(queries)\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "closest_n = 5\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n",
    "\n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (1-distance))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "\n",
    "%%time\n",
    "import os\n",
    "import tqdm\n",
    "import textwrap\n",
    "import json\n",
    "import prettytable\n",
    "import logging\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from  transformers import *\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "COVID_BROWSER_ASCII = \"\"\"\n",
    "================================================================================\n",
    "  _____           _     _      __  ___    ____                                  \n",
    " / ____|         (_)   | |    /_ |/ _ \\  |  _ \\                                 \n",
    "| |     _____   ___  __| | ___ | | (_) | | |_) |_ __ _____      _____  ___ _ __ \n",
    "| |    / _ \\ \\ / / |/ _` ||___|| |\\__, | |  _ <| '__/ _ \\ \\ /\\ / / __|/ _ \\ '__|\n",
    "| |___| (_) \\ V /| | (_| |     | |  / /  | |_) | | | (_) \\ V  V /\\__ \\  __/ |   \n",
    " \\_____\\___/ \\_/ |_|\\__,_|     |_| /_/   |____/|_|  \\___/ \\_/\\_/ |___/\\___|_|   \n",
    "=================================================================================\n",
    "\"\"\"\n",
    "\n",
    "COVID_BROWSER_INTRO = \"\"\"\n",
    "This demo uses a state-of-the-art language model trained on scientific papers to\n",
    "search passages matching user-defined queries inside the COVID-19 Open Research\n",
    "Dataset. Ask something like 'Is smoking a risk factor for Covid-19?' to retrieve\n",
    "relevant abstracts.\\n\n",
    "\"\"\"\n",
    "\n",
    "BIORXIV_PATH = '/kaggle/input/CORD-19-research-challenge//biorxiv_medrxiv/biorxiv_medrxiv/'\n",
    "COMM_USE_PATH = '/kaggle/input/CORD-19-research-challenge/comm_use_subset/comm_use_subset/'\n",
    "NONCOMM_USE_PATH = '/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/'\n",
    "METADATA_PATH = '/kaggle/input/CORD-19-research-challenge/metadata.csv'\n",
    "\n",
    "DATA_PATH = '/kaggle/input/CORD-19-research-challenge/'\n",
    "MODELS_PATH = 'models'\n",
    "MODEL_NAME = 'scibert-nli'\n",
    "CORPUS_PATH = os.path.join(DATA_PATH, 'corpus.pkl')\n",
    "MODEL_PATH = os.path.join(MODELS_PATH, MODEL_NAME)\n",
    "EMBEDDINGS_PATH = os.path.join(DATA_PATH, f'{MODEL_NAME}-embeddings.pkl')\n",
    "\n",
    "\n",
    "def load_json_files(dirname):\n",
    "    filenames = [file for file in os.listdir(dirname) if file.endswith('.json')]\n",
    "    raw_files = []\n",
    "\n",
    "    for filename in tqdm(filenames):\n",
    "        filename = dirname + filename\n",
    "        file = json.load(open(filename, 'rb'))\n",
    "        raw_files.append(file)\n",
    "    print('Loaded', len(raw_files), 'files from', dirname)\n",
    "    return raw_files\n",
    "\n",
    "\n",
    "def create_corpus_from_json(files):\n",
    "    corpus = []\n",
    "    for file in tqdm(files):\n",
    "        for item in file['abstract']:\n",
    "            corpus.append(item['text'])\n",
    "        for item in file['body_text']:\n",
    "            corpus.append(item['text'])\n",
    "    print('Corpus size', len(corpus))\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def cache_corpus(mode='CSV'):\n",
    "    corpus = []\n",
    "    if mode == 'CSV':\n",
    "        df = pd.read_csv(METADATA_PATH)\n",
    "        corpus = [a for a in df['abstract'] if type(a) == str and a != \"Unknown\"]\n",
    "        print('Corpus size', len(corpus))\n",
    "    elif mode == 'JSON':\n",
    "        biorxiv_files = load_json_files(BIORXIV_PATH)\n",
    "        comm_use_files = load_json_files(COMM_USE_PATH)\n",
    "        noncomm_use_files = load_json_files(NONCOMM_USE_PATH)\n",
    "        corpus = create_corpus_from_json(biorxiv_files + comm_use_files + noncomm_use_files)\n",
    "    else:\n",
    "        raise AttributeError('Mode should be either CSV or JSON')\n",
    "    '''with open(CORPUS_PATH, 'wb') as file:\n",
    "        pickle.dump(corpus, file)'''\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def ask_question(query, model, corpus, corpus_embed, top_k=5):\n",
    "    \"\"\"\n",
    "    Adapted from https://www.kaggle.com/dattaraj/risks-of-covid-19-ai-driven-q-a\n",
    "    \"\"\"\n",
    "    queries = [query]\n",
    "    query_embeds = model.encode(queries, show_progress_bar=False)\n",
    "    for query, query_embed in zip(queries, query_embeds):\n",
    "        distances = scipy.spatial.distance.cdist([query_embed], corpus_embed, \"cosine\")[0]\n",
    "        distances = zip(range(len(distances)), distances)\n",
    "        distances = sorted(distances, key=lambda x: x[1])\n",
    "        results = []\n",
    "        for count, (idx, distance) in enumerate(distances[0:top_k]):\n",
    "            results.append([count + 1, corpus[idx].strip(), round(1 - distance, 4)])\n",
    "    return results\n",
    "\n",
    "\n",
    "def show_answers(results):\n",
    "    table = prettytable.PrettyTable(\n",
    "        ['Rank', 'Abstract', 'Score']\n",
    "    )\n",
    "    for res in results:\n",
    "        rank = res[0]\n",
    "        text = res[1]\n",
    "        text = textwrap.fill(text, width=75)\n",
    "        text = text + '\\n\\n'\n",
    "        score = res[2]\n",
    "        table.add_row([\n",
    "            rank,\n",
    "            text,\n",
    "            score\n",
    "        ])\n",
    "    print('\\n')\n",
    "    print(str(table))\n",
    "    print('\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.system('cls' if os.name == 'nt' else 'clear')\n",
    "    print(COVID_BROWSER_ASCII)\n",
    "    print(COVID_BROWSER_INTRO)\n",
    "    if not os.path.exists(CORPUS_PATH):\n",
    "        print(\"Caching the corpus for future use...\")\n",
    "        corpus = cache_corpus()\n",
    "    else:\n",
    "        print(\"Loading the corpus from\", CORPUS_PATH, '...')\n",
    "        with open(CORPUS_PATH, 'rb') as corpus_pt:\n",
    "            corpus = pickle.load(corpus_pt)\n",
    "\n",
    "    model =  SentenceTransformer('bert-base-nli-stsb-mean-tokens')\n",
    "\n",
    "    if not os.path.exists(EMBEDDINGS_PATH):\n",
    "        print(\"Computing and caching model embeddings for future use...\")\n",
    "        embeddings = model.encode(corpus, show_progress_bar=True)\n",
    "        '''with open(EMBEDDINGS_PATH, 'wb') as file:\n",
    "            pickle.dump(embeddings, file)'''\n",
    "    else:\n",
    "        print(\"Loading model embeddings from\", EMBEDDINGS_PATH, '...')\n",
    "        with open(EMBEDDINGS_PATH, 'rb') as file:\n",
    "            embeddings = pickle.load(file)\n",
    "            \n",
    "            \n",
    "questions = ['Is smoking a risk factor for Covid-19?','What has been published about medical care?','Co-infections (determine whether co-existing respiratory/viral infections make the virus more transmissible or virulent) and other co-morbidities','risk for  Neonates and pregnant women?','Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.']\n",
    "for i in range(len(questions)):\n",
    "        query = questions[i]\n",
    "        print(f'Query {i+1} : {query}\\n\\n')\n",
    "        results = ask_question(query, model, corpus, embeddings)\n",
    "        show_answers(results)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
